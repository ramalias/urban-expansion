{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramalias/urban-expansion/blob/main/04_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7fcffb46",
      "metadata": {
        "id": "7fcffb46"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import geopandas as gpd\n",
        "from rasterio import features\n",
        "from rasterio.enums import Resampling\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from rasterio.warp import reproject, Resampling\n",
        "import glob\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Python:\", sys.executable)\n",
        "print(\"torch.__version__:\", torch.__version__)\n",
        "print(\"torch.version.cuda:\", torch.version.cuda)\n",
        "print(\"cuda available:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "zdTqs5PQQOHf",
        "outputId": "39cac160-0879-4535-e246-fc93446d4715",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zdTqs5PQQOHf",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: /usr/bin/python3\n",
            "torch.__version__: 2.9.0+cu126\n",
            "torch.version.cuda: 12.6\n",
            "cuda available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "iMwSRhlkQZuv",
        "outputId": "8ed21966-1210-4240-aa9c-1f047e871230",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "iMwSRhlkQZuv",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Dec  6 16:29:04 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_raster(path):\n",
        "    \"\"\"Load raster and return array + profile.\"\"\"\n",
        "    src = rasterio.open(path)\n",
        "    arr = src.read(1)\n",
        "    profile = src.profile\n",
        "    return arr, profile\n",
        "\n",
        "def save_raster(path, array, profile):\n",
        "    \"\"\"Save raster with given profile.\"\"\"\n",
        "    profile.update(dtype=rasterio.uint8, count=1)\n",
        "    with rasterio.open(path, \"w\", **profile) as dst:\n",
        "        dst.write(array.astype(\"uint8\"), 1)\n",
        "\n",
        "def rasterize_shapefile(gdf, reference_profile, attribute):\n",
        "    \"\"\"Rasterize shapefile according to reference raster.\"\"\"\n",
        "    shapes = [(geom, value) for geom, value in zip(gdf.geometry, gdf[attribute])]\n",
        "    raster = features.rasterize(\n",
        "        shapes=shapes,\n",
        "        out_shape=(reference_profile[\"height\"], reference_profile[\"width\"]),\n",
        "        transform=reference_profile[\"transform\"],\n",
        "        fill=0,\n",
        "        dtype=\"uint8\"\n",
        "    )\n",
        "    return raster"
      ],
      "metadata": {
        "id": "ekw2k6gCRLgP"
      },
      "id": "ekw2k6gCRLgP",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load final data"
      ],
      "metadata": {
        "id": "_Lhz98l_Qd0T"
      },
      "id": "_Lhz98l_Qd0T"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dM48pHnoQdgh",
        "outputId": "8c56a1a6-5530-49ed-b1e3-f00b1bb975e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dM48pHnoQdgh",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = r\"/content/drive/MyDrive/12-training-data\"\n",
        "\n",
        "# Feature rasters live directly inside BASE_DIR\n",
        "FEATURE_DIR = os.path.join(BASE_DIR, \"input\")\n",
        "FEATURE_DIR_ALIGNED_2019 = os.path.join(FEATURE_DIR, \"training-data-final2019\")\n",
        "FEATURE_DIR_ALIGNED_2024 = os.path.join(FEATURE_DIR, \"2024-data\")\n",
        "\n",
        "DEPENDENT_DIR = os.path.join(FEATURE_DIR, \"dependent-data-urban-no\")\n",
        "LANDCOVER_DIR = os.path.join(FEATURE_DIR, \"final-data-land-cover\")"
      ],
      "metadata": {
        "id": "Byi1wQ8UQbFW"
      },
      "id": "Byi1wQ8UQbFW",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(FEATURE_DIR)\n",
        "print(FEATURE_DIR_ALIGNED_2019)\n",
        "print(FEATURE_DIR_ALIGNED_2024)"
      ],
      "metadata": {
        "id": "2uHGzLX4QzWG",
        "outputId": "79c291a6-e615-42e5-f6b0-ab9cf024c770",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2uHGzLX4QzWG",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/12-training-data/input\n",
            "/content/drive/MyDrive/12-training-data/input/training-data-final2019\n",
            "/content/drive/MyDrive/12-training-data/input/2024-data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2019 data"
      ],
      "metadata": {
        "id": "grRmlptYgV9V"
      },
      "id": "grRmlptYgV9V"
    },
    {
      "cell_type": "code",
      "source": [
        "rasters_2019 = {\n",
        "    \"NDVI\": os.path.join(FEATURE_DIR, \"NDVI_2019.tif\"),\n",
        "    \"NDBI\": os.path.join(FEATURE_DIR, \"NDBI_2019.tif\"),\n",
        "    \"MNDWI\": os.path.join(FEATURE_DIR, \"MNDWI_2019.tif\"),\n",
        "    \"BSI\": os.path.join(FEATURE_DIR, \"BSI_2019.tif\"),\n",
        "    \"DEM\": os.path.join(FEATURE_DIR, \"DEM-DAegu-merged-clipmask.tif\"),\n",
        "    \"slope\": os.path.join(FEATURE_DIR, \"slope.tif\"),\n",
        "    \"aspect\": os.path.join(FEATURE_DIR, \"aspect.tif\"),\n",
        "    \"hillshade\": os.path.join(FEATURE_DIR, \"hillshade.tif\"),\n",
        "    \"night\": os.path.join(FEATURE_DIR, \"VNL_2019_daegu_clipped.tif\"),\n",
        "    \"ecology\": os.path.join(FEATURE_DIR, \"env-assessment-data-2019.tif\"),\n",
        "}"
      ],
      "metadata": {
        "id": "Z88mmkgHQ0yk"
      },
      "id": "Z88mmkgHQ0yk",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_arrays_2019 = {}\n",
        "feature_profiles = {}\n",
        "\n",
        "print(\"Loading 2019 rasters...\\n\")\n",
        "\n",
        "for name, path in rasters_2019.items():\n",
        "    arr, profile = load_raster(path)\n",
        "    feature_arrays[name] = arr\n",
        "    feature_profiles[name] = profile\n",
        "    print(f\"{name} loaded → shape: {arr.shape}\")"
      ],
      "metadata": {
        "id": "Z_4mF9zIRAxf",
        "outputId": "aa9d2c7b-78d5-4adc-f786-2889727cacb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Z_4mF9zIRAxf",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 2019 rasters...\n",
            "\n",
            "NDVI loaded → shape: (4531, 3714)\n",
            "NDBI loaded → shape: (4531, 3714)\n",
            "MNDWI loaded → shape: (4531, 3714)\n",
            "BSI loaded → shape: (4531, 3714)\n",
            "DEM loaded → shape: (1622, 1330)\n",
            "slope loaded → shape: (1622, 1330)\n",
            "aspect loaded → shape: (1622, 1330)\n",
            "hillshade loaded → shape: (1622, 1330)\n",
            "night loaded → shape: (99, 100)\n",
            "ecology loaded → shape: (4590, 3684)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aligned_arrays_2019 = {\n",
        "    \"NDVI\": rasters_2019[\"NDVI\"],     # Use original path\n",
        "    \"NDBI\": rasters_2019[\"NDBI\"],\n",
        "    \"MNDWI\": rasters_2019[\"MNDWI\"],\n",
        "    \"BSI\": rasters_2019[\"BSI\"],\n",
        "\n",
        "    \"DEM\": os.path.join(FEATURE_DIR_ALIGNED_2019, \"DEM_aligned.tif\"),\n",
        "    \"slope\": os.path.join(FEATURE_DIR_ALIGNED_2019, \"slope_aligned.tif\"),\n",
        "    \"aspect\": os.path.join(FEATURE_DIR_ALIGNED_2019, \"aspect_aligned.tif\"),\n",
        "    \"hillshade\": os.path.join(FEATURE_DIR_ALIGNED_2019, \"hillshade_aligned.tif\"),\n",
        "    \"night\": os.path.join(FEATURE_DIR_ALIGNED_2019, \"night_aligned.tif\"),\n",
        "    \"ecology\": os.path.join(FEATURE_DIR_ALIGNED_2019, \"ecology_aligned.tif\"),\n",
        "}"
      ],
      "metadata": {
        "id": "BR-GgJbSRCmm"
      },
      "id": "BR-GgJbSRCmm",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_align_arrays_2019 = {}\n",
        "feature_profiles = {}\n",
        "\n",
        "print(\"Loading aligned raster data...\\n\")\n",
        "\n",
        "for name, path in aligned_arrays_2019.items():\n",
        "    arr, profile = load_raster(path)\n",
        "    feature_align_arrays_2019[name] = arr\n",
        "    feature_profiles[name] = profile\n",
        "    print(f\"{name} loaded → shape: {arr.shape}\")"
      ],
      "metadata": {
        "id": "RKeXOq12RTH_",
        "outputId": "b17b6bcd-e1e8-4c56-cb9a-74e8545148b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "RKeXOq12RTH_",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading aligned raster data...\n",
            "\n",
            "NDVI loaded → shape: (4531, 3714)\n",
            "NDBI loaded → shape: (4531, 3714)\n",
            "MNDWI loaded → shape: (4531, 3714)\n",
            "BSI loaded → shape: (4531, 3714)\n",
            "DEM loaded → shape: (4531, 3714)\n",
            "slope loaded → shape: (4531, 3714)\n",
            "aspect loaded → shape: (4531, 3714)\n",
            "hillshade loaded → shape: (4531, 3714)\n",
            "night loaded → shape: (4531, 3714)\n",
            "ecology loaded → shape: (4531, 3714)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reference_profile = feature_profiles[\"NDVI\"]\n",
        "ref_crs = reference_profile[\"crs\"]\n",
        "ref_res = reference_profile[\"transform\"][0]\n",
        "ref_width, ref_height = reference_profile[\"width\"], reference_profile[\"height\"]\n",
        "ref_bounds = rasterio.open(rasters_2019[\"NDVI\"]).bounds\n",
        "\n",
        "print(\"REFERENCE NDVI:\")\n",
        "print(\"  CRS:\", ref_crs)\n",
        "print(\"  Res:\", ref_res)\n",
        "print(\"  Size:\", ref_height, \"x\", ref_width)\n",
        "print(\"  Bounds:\", ref_bounds)\n",
        "print(\"--------------------------------------------------\")\n",
        "\n",
        "for name, path in aligned_arrays_2019.items():\n",
        "    with rasterio.open(path) as src:\n",
        "        print(f\"Raster: {name}\")\n",
        "        print(\"  CRS:\", src.crs)\n",
        "        print(\"  Res:\", src.res)\n",
        "        print(\"  Size:\", src.height, \"x\", src.width)\n",
        "        print(\"  Bounds:\", src.bounds)\n",
        "        print(\"  SAME CRS?\", src.crs == ref_crs)\n",
        "        print(\"  SAME RES?\", src.res[0] == ref_res)\n",
        "        print(\"  SAME SIZE?\", (src.height == ref_height) and (src.width == ref_width))\n",
        "        print(\"--------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlfWEAbMgsa7",
        "outputId": "479addf1-7df9-4bbf-a662-7c4908ee1392"
      },
      "id": "WlfWEAbMgsa7",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REFERENCE NDVI:\n",
            "  CRS: EPSG:32652\n",
            "  Res: 10.0\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "--------------------------------------------------\n",
            "Raster: NDVI\n",
            "  CRS: EPSG:32652\n",
            "  Res: (10.0, 10.0)\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "  SAME CRS? True\n",
            "  SAME RES? True\n",
            "  SAME SIZE? True\n",
            "--------------------------------------------------\n",
            "Raster: NDBI\n",
            "  CRS: EPSG:32652\n",
            "  Res: (10.0, 10.0)\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "  SAME CRS? True\n",
            "  SAME RES? True\n",
            "  SAME SIZE? True\n",
            "--------------------------------------------------\n",
            "Raster: MNDWI\n",
            "  CRS: EPSG:32652\n",
            "  Res: (10.0, 10.0)\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "  SAME CRS? True\n",
            "  SAME RES? True\n",
            "  SAME SIZE? True\n",
            "--------------------------------------------------\n",
            "Raster: BSI\n",
            "  CRS: EPSG:32652\n",
            "  Res: (10.0, 10.0)\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "  SAME CRS? True\n",
            "  SAME RES? True\n",
            "  SAME SIZE? True\n",
            "--------------------------------------------------\n",
            "Raster: DEM\n",
            "  CRS: EPSG:32652\n",
            "  Res: (10.0, 10.0)\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "  SAME CRS? True\n",
            "  SAME RES? True\n",
            "  SAME SIZE? True\n",
            "--------------------------------------------------\n",
            "Raster: slope\n",
            "  CRS: EPSG:32652\n",
            "  Res: (10.0, 10.0)\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "  SAME CRS? True\n",
            "  SAME RES? True\n",
            "  SAME SIZE? True\n",
            "--------------------------------------------------\n",
            "Raster: aspect\n",
            "  CRS: EPSG:32652\n",
            "  Res: (10.0, 10.0)\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "  SAME CRS? True\n",
            "  SAME RES? True\n",
            "  SAME SIZE? True\n",
            "--------------------------------------------------\n",
            "Raster: hillshade\n",
            "  CRS: EPSG:32652\n",
            "  Res: (10.0, 10.0)\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "  SAME CRS? True\n",
            "  SAME RES? True\n",
            "  SAME SIZE? True\n",
            "--------------------------------------------------\n",
            "Raster: night\n",
            "  CRS: EPSG:32652\n",
            "  Res: (10.0, 10.0)\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "  SAME CRS? True\n",
            "  SAME RES? True\n",
            "  SAME SIZE? True\n",
            "--------------------------------------------------\n",
            "Raster: ecology\n",
            "  CRS: EPSG:32652\n",
            "  Res: (10.0, 10.0)\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "  SAME CRS? True\n",
            "  SAME RES? True\n",
            "  SAME SIZE? True\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2024 data"
      ],
      "metadata": {
        "id": "pT68H62fgYLm"
      },
      "id": "pT68H62fgYLm"
    },
    {
      "cell_type": "code",
      "source": [
        "rasters_2024 = {\n",
        "    \"NDVI\": os.path.join(FEATURE_DIR_ALIGNED_2024, \"NDVI_2024.tif\"),\n",
        "    \"NDBI\": os.path.join(FEATURE_DIR_ALIGNED_2024, \"NDBI_2024.tif\"),\n",
        "    \"MNDWI\": os.path.join(FEATURE_DIR_ALIGNED_2024, \"MNDWI_2024.tif\"),\n",
        "    \"BSI\": os.path.join(FEATURE_DIR_ALIGNED_2024, \"BSI_2024.tif\"),\n",
        "    \"DEM\": os.path.join(FEATURE_DIR, \"DEM-DAegu-merged-clipmask.tif\"),\n",
        "    \"slope\": os.path.join(FEATURE_DIR_ALIGNED_2024, \"slope.tif\"),\n",
        "    \"aspect\": os.path.join(FEATURE_DIR_ALIGNED_2024, \"aspect.tif\"),\n",
        "    \"hillshade\": os.path.join(FEATURE_DIR_ALIGNED_2024, \"hillshade.tif\"),\n",
        "    \"night\": os.path.join(FEATURE_DIR_ALIGNED_2024, \"VNL_2024_daegu_clipped.tif\"),\n",
        "    \"ecology\": os.path.join(FEATURE_DIR_ALIGNED_2024, \"env-assessment-data-2024.tif\"),\n",
        "}"
      ],
      "metadata": {
        "id": "K1TnE9RLhDoT"
      },
      "id": "K1TnE9RLhDoT",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_arrays_2024 = {}\n",
        "feature_profiles = {}\n",
        "\n",
        "print(\"Loading 2024 rasters...\\n\")\n",
        "\n",
        "for name, path in rasters_2024.items():\n",
        "    arr, profile = load_raster(path)\n",
        "    feature_arrays[name] = arr\n",
        "    feature_profiles[name] = profile\n",
        "    print(f\"{name} loaded → shape: {arr.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUKeprtehfOs",
        "outputId": "61ceb3cd-9bc6-4151-8327-266ab8bc7c44"
      },
      "id": "yUKeprtehfOs",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 2024 rasters...\n",
            "\n",
            "NDVI loaded → shape: (4531, 3714)\n",
            "NDBI loaded → shape: (4531, 3714)\n",
            "MNDWI loaded → shape: (4531, 3714)\n",
            "BSI loaded → shape: (4531, 3714)\n",
            "DEM loaded → shape: (1622, 1330)\n",
            "slope loaded → shape: (1622, 1330)\n",
            "aspect loaded → shape: (1622, 1330)\n",
            "hillshade loaded → shape: (1622, 1330)\n",
            "night loaded → shape: (99, 100)\n",
            "ecology loaded → shape: (9180, 7368)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aligned_arrays_2024 = {\n",
        "    \"NDVI\": rasters_2024[\"NDVI\"],     # Use original path\n",
        "    \"NDBI\": rasters_2024[\"NDBI\"],\n",
        "    \"MNDWI\": rasters_2024[\"MNDWI\"],\n",
        "    \"BSI\": rasters_2024[\"BSI\"],\n",
        "\n",
        "    \"DEM\": os.path.join(FEATURE_DIR_ALIGNED_2024, \"DEM_aligned.tif\"),\n",
        "    \"slope\": os.path.join(FEATURE_DIR_ALIGNED_2024, \"slope_aligned.tif\"),\n",
        "    \"aspect\": os.path.join(FEATURE_DIR_ALIGNED_2024, \"aspect_aligned.tif\"),\n",
        "    \"hillshade\": os.path.join(FEATURE_DIR_ALIGNED_2024, \"hillshade_aligned.tif\"),\n",
        "    \"night\": os.path.join(FEATURE_DIR_ALIGNED_2024, \"night_aligned.tif\"),\n",
        "    \"ecology\": os.path.join(FEATURE_DIR_ALIGNED_2024, \"ecology_aligned.tif\"),\n",
        "}"
      ],
      "metadata": {
        "id": "wC1QenxchOiD"
      },
      "id": "wC1QenxchOiD",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_align_arrays_2024 = {}\n",
        "feature_profiles = {}\n",
        "\n",
        "print(\"Loading aligned data 2024...\\n\")\n",
        "\n",
        "for name, path in aligned_arrays.items():\n",
        "    arr, profile = load_raster(path)\n",
        "    feature_align_arrays_2024[name] = arr\n",
        "    feature_profiles[name] = profile\n",
        "    print(f\"{name} loaded → shape: {arr.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnLoFrSmhuRS",
        "outputId": "6c6cc107-93db-4bb6-90cf-09996d44cffa"
      },
      "id": "xnLoFrSmhuRS",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading aligned data 2024...\n",
            "\n",
            "NDVI loaded → shape: (4531, 3714)\n",
            "NDBI loaded → shape: (4531, 3714)\n",
            "MNDWI loaded → shape: (4531, 3714)\n",
            "BSI loaded → shape: (4531, 3714)\n",
            "DEM loaded → shape: (4531, 3714)\n",
            "slope loaded → shape: (4531, 3714)\n",
            "hillshade loaded → shape: (4531, 3714)\n",
            "night loaded → shape: (4531, 3714)\n",
            "ecology loaded → shape: (4531, 3714)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reference_profile = feature_profiles[\"NDVI\"]\n",
        "ref_crs = reference_profile[\"crs\"]\n",
        "ref_res = reference_profile[\"transform\"][0]\n",
        "ref_width, ref_height = reference_profile[\"width\"], reference_profile[\"height\"]\n",
        "ref_bounds = rasterio.open(rasters_2019[\"NDVI\"]).bounds\n",
        "\n",
        "print(\"REFERENCE NDVI:\")\n",
        "print(\"  CRS:\", ref_crs)\n",
        "print(\"  Res:\", ref_res)\n",
        "print(\"  Size:\", ref_height, \"x\", ref_width)\n",
        "print(\"  Bounds:\", ref_bounds)\n",
        "print(\"--------------------------------------------------\")\n",
        "\n",
        "for name, path in aligned_arrays_2024.items():\n",
        "    with rasterio.open(path) as src:\n",
        "        print(f\"Raster: {name}\")\n",
        "        print(\"  CRS:\", src.crs)\n",
        "        print(\"  Res:\", src.res)\n",
        "        print(\"  Size:\", src.height, \"x\", src.width)\n",
        "        print(\"  Bounds:\", src.bounds)\n",
        "        print(\"  SAME CRS?\", src.crs == ref_crs)\n",
        "        print(\"  SAME RES?\", src.res[0] == ref_res)\n",
        "        print(\"  SAME SIZE?\", (src.height == ref_height) and (src.width == ref_width))\n",
        "        print(\"--------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-93HJFnYhzs_",
        "outputId": "7cce3887-98db-4165-adbb-eae8c18a4152"
      },
      "id": "-93HJFnYhzs_",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REFERENCE NDVI:\n",
            "  CRS: EPSG:32652\n",
            "  Res: 10.0\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "--------------------------------------------------\n",
            "Raster: NDVI\n",
            "  CRS: EPSG:32652\n",
            "  Res: (10.0, 10.0)\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "  SAME CRS? True\n",
            "  SAME RES? True\n",
            "  SAME SIZE? True\n",
            "--------------------------------------------------\n",
            "Raster: NDBI\n",
            "  CRS: EPSG:32652\n",
            "  Res: (10.0, 10.0)\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "  SAME CRS? True\n",
            "  SAME RES? True\n",
            "  SAME SIZE? True\n",
            "--------------------------------------------------\n",
            "Raster: MNDWI\n",
            "  CRS: EPSG:32652\n",
            "  Res: (10.0, 10.0)\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "  SAME CRS? True\n",
            "  SAME RES? True\n",
            "  SAME SIZE? True\n",
            "--------------------------------------------------\n",
            "Raster: BSI\n",
            "  CRS: EPSG:32652\n",
            "  Res: (10.0, 10.0)\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "  SAME CRS? True\n",
            "  SAME RES? True\n",
            "  SAME SIZE? True\n",
            "--------------------------------------------------\n",
            "Raster: DEM\n",
            "  CRS: EPSG:32652\n",
            "  Res: (10.0, 10.0)\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "  SAME CRS? True\n",
            "  SAME RES? True\n",
            "  SAME SIZE? True\n",
            "--------------------------------------------------\n",
            "Raster: slope\n",
            "  CRS: EPSG:32652\n",
            "  Res: (10.0, 10.0)\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "  SAME CRS? True\n",
            "  SAME RES? True\n",
            "  SAME SIZE? True\n",
            "--------------------------------------------------\n",
            "Raster: aspect\n",
            "  CRS: EPSG:32652\n",
            "  Res: (10.0, 10.0)\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "  SAME CRS? True\n",
            "  SAME RES? True\n",
            "  SAME SIZE? True\n",
            "--------------------------------------------------\n",
            "Raster: hillshade\n",
            "  CRS: EPSG:32652\n",
            "  Res: (10.0, 10.0)\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "  SAME CRS? True\n",
            "  SAME RES? True\n",
            "  SAME SIZE? True\n",
            "--------------------------------------------------\n",
            "Raster: night\n",
            "  CRS: EPSG:32652\n",
            "  Res: (10.0, 10.0)\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "  SAME CRS? True\n",
            "  SAME RES? True\n",
            "  SAME SIZE? True\n",
            "--------------------------------------------------\n",
            "Raster: ecology\n",
            "  CRS: EPSG:32652\n",
            "  Res: (10.0, 10.0)\n",
            "  Size: 4531 x 3714\n",
            "  Bounds: BoundingBox(left=441320.0, bottom=3940480.0, right=478460.0, top=3985790.0)\n",
            "  SAME CRS? True\n",
            "  SAME RES? True\n",
            "  SAME SIZE? True\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# urban classification"
      ],
      "metadata": {
        "id": "JbnJXs9xh79Z"
      },
      "id": "JbnJXs9xh79Z"
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "urban19_path = os.path.join(DEPENDENT_DIR, \"urban_2019.tif\")\n",
        "urban24_path = os.path.join(DEPENDENT_DIR, \"urban_2024.tif\")\n",
        "\n",
        "# Load both rasters\n",
        "with rasterio.open(urban19_path) as src19:\n",
        "    u19 = src19.read(1)\n",
        "    profile = src19.profile\n",
        "\n",
        "with rasterio.open(urban24_path) as src24:\n",
        "    u24 = src24.read(1)\n",
        "\n",
        "# Create output label array\n",
        "label = np.zeros_like(u19, dtype=np.uint8)\n",
        "\n",
        "# 1 = became urban (2019 nonurban → 2024 urban)\n",
        "label[(u19 == 0) & (u24 == 1)] = 1\n",
        "\n",
        "# 0 = stayed nonurban (2019 nonurban → 2024 nonurban)\n",
        "label[(u19 == 0) & (u24 == 0)] = 0\n",
        "\n",
        "# 255 = ignore (urban already in 2019, or urban→nonurban)\n",
        "label[(u19 == 1)] = 255\n",
        "\n",
        "# Save output\n",
        "profile.update(dtype=rasterio.uint8, nodata=255)\n",
        "\n",
        "output_path = os.path.join(DEPENDENT_DIR, \"urban_no_urban.tif\")\n",
        "with rasterio.open(output_path, \"w\", **profile) as dst:\n",
        "    dst.write(label, 1)\n",
        "\n",
        "print(\"Saved:\", output_path)\n"
      ],
      "metadata": {
        "id": "tKTLiMpkR29g",
        "outputId": "74f53de1-e9b7-4dde-d58e-73f2a82a68ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tKTLiMpkR29g",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/drive/MyDrive/12-training-data/input/dependent-data-urban-no/urban_no_urban.tif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(label, return_counts=True)\n",
        "print(list(zip(unique, counts)))"
      ],
      "metadata": {
        "id": "HnCMtL18SF4f",
        "outputId": "e882e54a-551c-4067-eff1-0fd5cd1b46a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HnCMtL18SF4f",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(np.uint8(0), np.int64(14286520)), (np.uint8(1), np.int64(265903)), (np.uint8(255), np.int64(2275711))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stacked Array"
      ],
      "metadata": {
        "id": "baLZY-V0RfFN"
      },
      "id": "baLZY-V0RfFN"
    },
    {
      "cell_type": "code",
      "source": [
        "# normalization\n",
        "def normalize(arr):\n",
        "    \"\"\"Min-max normalize array to 0–1.\"\"\"\n",
        "    arr = arr.astype(np.float32)\n",
        "    mn, mx = np.nanmin(arr), np.nanmax(arr)\n",
        "    if mx - mn == 0:\n",
        "        return np.zeros_like(arr)\n",
        "    return (arr - mn) / (mx - mn)\n",
        "\n",
        "#normalize all aligned feature\n",
        "normalized_features = {}\n",
        "for name, arr in feature_align_arrays_2019.items():\n",
        "    norm_arr = normalize(arr)\n",
        "    normalized_features[name] = norm_arr\n",
        "    print(f\"{name:12} normalized → min={norm_arr.min():.3f}, max={norm_arr.max():.3f}\")\n",
        "\n",
        "print(\"\\nAll features normalized.\\n\")\n",
        "\n",
        "# load dependent label raster (urban/no urban)\n",
        "label_path = os.path.join(DEPENDENT_DIR, \"urban_no_urban.tif\")\n",
        "\n",
        "with rasterio.open(label_path) as src:\n",
        "    y = src.read(1)\n",
        "    label_nodata = src.nodata\n",
        "    print(\"Label shape:\", y.shape)\n",
        "    print(\"Label nodata:\", label_nodata)\n",
        "\n",
        "# Create valid mask (True = usable pixel)\n",
        "if label_nodata is None:\n",
        "    label_mask = np.ones_like(y, dtype=bool)\n",
        "else:\n",
        "    label_mask = (y != label_nodata)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 4. STACK FEATURES INTO X (H, W, C)\n",
        "# ----------------------------------------------------\n",
        "feature_list = []\n",
        "feature_names = []\n",
        "\n",
        "for name, arr in normalized_features.items():\n",
        "    feature_list.append(arr)\n",
        "    feature_names.append(name)\n",
        "\n",
        "# Stack: output shape (H, W, C)\n",
        "X = np.stack(feature_list, axis=-1)\n",
        "\n",
        "print(\"\\n====================\")\n",
        "print(\"STACKED ARRAY READY!\")\n",
        "print(\"====================\")\n",
        "print(\"X shape:\", X.shape)         # (H, W, C)\n",
        "print(\"y shape:\", y.shape)         # (H, W)\n",
        "print(\"Feature order:\", feature_names)"
      ],
      "metadata": {
        "id": "-z90UVhFRaAK",
        "outputId": "ad3fb3e0-1cb2-46a9-a7a2-6fd4d8b97012",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-z90UVhFRaAK",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NDVI         normalized → min=0.000, max=1.000\n",
            "NDBI         normalized → min=0.000, max=1.000\n",
            "MNDWI        normalized → min=0.000, max=1.000\n",
            "BSI          normalized → min=0.000, max=1.000\n",
            "DEM          normalized → min=0.000, max=1.000\n",
            "slope        normalized → min=0.000, max=1.000\n",
            "aspect       normalized → min=0.000, max=1.000\n",
            "hillshade    normalized → min=0.000, max=1.000\n",
            "night        normalized → min=0.000, max=1.000\n",
            "ecology      normalized → min=0.000, max=1.000\n",
            "\n",
            "All features normalized.\n",
            "\n",
            "Label shape: (4531, 3714)\n",
            "Label nodata: 255.0\n",
            "\n",
            "====================\n",
            "STACKED ARRAY READY!\n",
            "====================\n",
            "X shape: (4531, 3714, 10)\n",
            "y shape: (4531, 3714)\n",
            "Feature order: ['NDVI', 'NDBI', 'MNDWI', 'BSI', 'DEM', 'slope', 'aspect', 'hillshade', 'night', 'ecology']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Patch Extraction Code\n",
        "\n",
        "// run only when want to extract"
      ],
      "metadata": {
        "id": "SLmFcidKSRit"
      },
      "id": "SLmFcidKSRit"
    },
    {
      "cell_type": "code",
      "source": [
        "PATCH_SIZE = 64\n",
        "STRIDE = 32\n",
        "\n",
        "X = X\n",
        "y = y\n",
        "\n",
        "# Where to save patches\n",
        "PATCH_DIR = os.path.join(BASE_DIR, \"patches\")\n",
        "os.makedirs(PATCH_DIR, exist_ok=True)\n",
        "os.makedirs(os.path.join(PATCH_DIR, \"X\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(PATCH_DIR, \"y\"), exist_ok=True)\n",
        "\n",
        "h, w, c = X.shape\n",
        "print(\"Raster size:\", h, w)\n",
        "print(\"Channels:\", c)\n",
        "\n",
        "patch_id = 0\n",
        "\n",
        "for row in tqdm(range(0, h - PATCH_SIZE, STRIDE)):\n",
        "    for col in range(0, w - PATCH_SIZE, STRIDE):\n",
        "\n",
        "        X_patch = X[row:row+PATCH_SIZE, col:col+PATCH_SIZE, :]\n",
        "        y_patch = y[row:row+PATCH_SIZE, col:col+PATCH_SIZE]\n",
        "\n",
        "        # Skip patches where all labels are 255\n",
        "        if np.all(y_patch == 255):\n",
        "            continue\n",
        "\n",
        "        # Optional: keep all patches that contain ANY urbanization (label=1)\n",
        "        # This improves class balance\n",
        "        if (1 in y_patch):\n",
        "            pass  # keep\n",
        "        else:\n",
        "            # Keep only 20% of negative patches (random sampling)\n",
        "            if np.random.rand() > 0.20:\n",
        "                continue\n",
        "\n",
        "        # Save patch\n",
        "        np.save(os.path.join(PATCH_DIR, \"X\", f\"X_{patch_id}.npy\"), X_patch)\n",
        "        np.save(os.path.join(PATCH_DIR, \"y\", f\"y_{patch_id}.npy\"), y_patch)\n",
        "\n",
        "        patch_id += 1\n",
        "\n",
        "print(\"Total patches saved:\", patch_id)\n"
      ],
      "metadata": {
        "id": "u1V4Z1d0SRN3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c11e2c2-ee51-4c7d-cc42-7933dc7366b4"
      },
      "id": "u1V4Z1d0SRN3",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raster size: 4531 3714\n",
            "Channels: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 140/140 [1:19:02<00:00, 33.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total patches saved: 10762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "\n",
        "2019 data -- feature (independent)\n",
        "\n",
        "NDVI, NDBI, MNDWI, BSI, ecology (env assessment data), lightime data\n",
        "\n",
        "urban change data (2024 - 2019) -- label (dependent)"
      ],
      "metadata": {
        "id": "H5EAjyqeShyy"
      },
      "id": "H5EAjyqeShyy"
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = r\"/content/drive/MyDrive/12-training-data\"\n",
        "PATCH_DIR = os.path.join(BASE_DIR, \"patches\")   # PATCH_SIZE = 64\n",
        "PATCH_SIZE = 64\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 300\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"DEVICE:\", DEVICE)\n",
        "\n",
        "NUM_FEATURE_BANDS = 10\n",
        "MODEL_OUT = os.path.join(BASE_DIR, \"models_300\")\n",
        "os.makedirs(MODEL_OUT, exist_ok=True)"
      ],
      "metadata": {
        "id": "9nsKTbunRiYR",
        "outputId": "9b625f20-136f-4d2b-f9ca-b7a08f44fec2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9nsKTbunRiYR",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchDataset(Dataset):\n",
        "    def __init__(self, x_files, y_files, augment=True):\n",
        "        self.x_files = x_files\n",
        "        self.y_files = y_files\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = np.load(self.x_files[idx]).astype(np.float32)      # (H, W, C)\n",
        "        y = np.load(self.y_files[idx]).astype(np.uint8)        # (H, W)\n",
        "\n",
        "        # Add assertion to check patch dimensions\n",
        "        assert x.shape[0] == PATCH_SIZE and x.shape[1] == PATCH_SIZE, \\\n",
        "            f\"X patch size mismatch: Expected ({PATCH_SIZE}, {PATCH_SIZE}), got {x.shape[:2]} for {self.x_files[idx]}\"\n",
        "        assert y.shape[0] == PATCH_SIZE and y.shape[1] == PATCH_SIZE, \\\n",
        "            f\"Y patch size mismatch: Expected ({PATCH_SIZE}, {PATCH_SIZE}), got {y.shape} for {self.y_files[idx]}\"\n",
        "\n",
        "        x = torch.from_numpy(x).permute(2, 0, 1)               # -> (C, H, W)\n",
        "        y = torch.from_numpy(y).float().unsqueeze(0)           # -> (1, H, W)\n",
        "\n",
        "        # clamp ignore 255 → 0 because DL expects 0/1\n",
        "        y = torch.clamp(y, 0, 1)\n",
        "\n",
        "        if self.augment:\n",
        "            x, y = self._augment(x, y)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def _augment(self, x, y):\n",
        "        if np.random.rand() > 0.5:\n",
        "            x = TF.hflip(x); y = TF.hflip(y)\n",
        "        if np.random.rand() > 0.5:\n",
        "            x = TF.vflip(x); y = TF.vflip(y)\n",
        "        k = np.random.randint(4)\n",
        "        if k:\n",
        "            x = torch.rot90(x, k, [1,2])\n",
        "            y = torch.rot90(y, k, [1,2])\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "auJycWffTxRA"
      },
      "id": "auJycWffTxRA",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# UNet Model\n",
        "# -----------------------\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=9, out_channels=1, features=[64, 128, 256, 512]):\n",
        "        super().__init__()\n",
        "        self.downs = nn.ModuleList()\n",
        "        self.ups = nn.ModuleList()\n",
        "\n",
        "        # Downsampling layers\n",
        "        for feat in features:\n",
        "            self.downs.append(ConvBlock(in_channels, feat))\n",
        "            in_channels = feat\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = ConvBlock(features[-1], features[-1]*2)\n",
        "\n",
        "        # Upsampling layers\n",
        "        for feat in reversed(features):\n",
        "            self.ups.append(nn.ConvTranspose2d(feat*2, feat, kernel_size=2, stride=2))\n",
        "            self.ups.append(ConvBlock(feat*2, feat))\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "\n",
        "        # Down path\n",
        "        for down in self.downs:\n",
        "            x = down(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        # Bottleneck\n",
        "        x = self.bottleneck(x)\n",
        "        skip_connections = skip_connections[::-1]\n",
        "\n",
        "        # Up path\n",
        "        for idx in range(0, len(self.ups), 2):\n",
        "            x = self.ups[idx](x)\n",
        "            skip = skip_connections[idx//2]\n",
        "            if x.shape != skip.shape:\n",
        "                skip = TF.center_crop(skip, (x.shape[2], x.shape[3]))\n",
        "            x = torch.cat((skip, x), dim=1)\n",
        "            x = self.ups[idx+1](x)\n",
        "\n",
        "        return self.final_conv(x)"
      ],
      "metadata": {
        "id": "OCWHS33gTxux"
      },
      "id": "OCWHS33gTxux",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# LOSS FUNCTIONS\n",
        "# -----------------------\n",
        "def dice_loss(pred, target, eps=1e-6):\n",
        "    pred = torch.sigmoid(pred)\n",
        "    intersection = (pred * target).sum()\n",
        "    union = pred.sum() + target.sum()\n",
        "    return 1 - (2*intersection + eps) / (union + eps)\n",
        "\n",
        "\n",
        "class BCEDiceLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        loss_bce = self.bce(logits, targets)\n",
        "        loss_dice = dice_loss(logits, targets)\n",
        "        return loss_bce + loss_dice"
      ],
      "metadata": {
        "id": "N4v8OarAT2cG"
      },
      "id": "N4v8OarAT2cG",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# LOAD PATCHES\n",
        "# -----------------------\n",
        "x_files = sorted(glob.glob(os.path.join(PATCH_DIR, \"X\", \"*.npy\")))\n",
        "y_files = sorted(glob.glob(os.path.join(PATCH_DIR, \"y\", \"*.npy\")))\n",
        "\n",
        "print(\"Total patches found:\", len(x_files))\n",
        "\n",
        "train_x, val_x, train_y, val_y = train_test_split(\n",
        "    x_files, y_files, test_size=0.10, random_state=42\n",
        ")\n",
        "\n",
        "train_ds = PatchDataset(train_x, train_y, augment=True)\n",
        "val_ds   = PatchDataset(val_x, val_y, augment=False)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}\")"
      ],
      "metadata": {
        "id": "UfdWSRIcT6Rz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b6cfdc3-2708-4329-aaf8-d98e59e8ded8"
      },
      "id": "UfdWSRIcT6Rz",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total patches found: 10850\n",
            "Train: 9765, Val: 1085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# TRAINING SETUP\n",
        "# -----------------------\n",
        "model = UNet(in_channels=NUM_FEATURE_BANDS).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = BCEDiceLoss()\n",
        "\n",
        "best_f1 = 0.0"
      ],
      "metadata": {
        "id": "GQMmkGI5T87L"
      },
      "id": "GQMmkGI5T87L",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = {\n",
        "    \"train_loss\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"precision\": [],\n",
        "    \"recall\": [],\n",
        "    \"f1\": [],\n",
        "    \"accuracy\": []\n",
        "}\n"
      ],
      "metadata": {
        "id": "-ywb54K9UKo5"
      },
      "id": "-ywb54K9UKo5",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# TRAINING LOOP\n",
        "# -----------------------\n",
        "def threshold_logits(logits, thresh=0.5):\n",
        "    return (torch.sigmoid(logits) > thresh).float()\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for xb, yb in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\"):\n",
        "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * xb.size(0)\n",
        "\n",
        "    train_loss /= len(train_ds)\n",
        "\n",
        "    # -----------------------\n",
        "    # VALIDATION\n",
        "    # -----------------------\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    tp=fp=fn=tn=0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "            val_loss += loss.item() * xb.size(0)\n",
        "\n",
        "            preds = threshold_logits(logits)\n",
        "\n",
        "            # Flatten\n",
        "            preds_f = preds.view(-1)\n",
        "            yb_f = yb.view(-1)\n",
        "\n",
        "            tp += ((preds_f==1) & (yb_f==1)).sum().item()\n",
        "            tn += ((preds_f==0) & (yb_f==0)).sum().item()\n",
        "            fp += ((preds_f==1) & (yb_f==0)).sum().item()\n",
        "            fn += ((preds_f==0) & (yb_f==1)).sum().item()\n",
        "\n",
        "    val_loss /= len(val_ds)\n",
        "    precision = tp / (tp + fp + 1e-9)\n",
        "    recall    = tp / (tp + fn + 1e-9)\n",
        "    f1        = 2 * precision * recall / (precision + recall + 1e-9)\n",
        "    acc       = (tp + tn) / (tp + tn + fp + fn + 1e-9)\n",
        "\n",
        "    # -----------------------\n",
        "    # STORE METRICS\n",
        "    # -----------------------\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "    history[\"precision\"].append(precision)\n",
        "    history[\"recall\"].append(recall)\n",
        "    history[\"f1\"].append(f1)\n",
        "    history[\"accuracy\"].append(acc)\n",
        "\n",
        "    # -----------------------\n",
        "    # LIVE PLOTTING\n",
        "    # -----------------------\n",
        "    clear_output(wait=True)\n",
        "    plt.figure(figsize=(16,4))\n",
        "\n",
        "    # LOSS CURVE\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
        "    plt.plot(history[\"val_loss\"], label=\"Val Loss\")\n",
        "    plt.title(\"Loss Curve\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    # F1 / PRECISION / RECALL\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(history[\"f1\"], label=\"F1 Score\")\n",
        "    plt.plot(history[\"precision\"], label=\"Precision\")\n",
        "    plt.plot(history[\"recall\"], label=\"Recall\")\n",
        "    plt.title(\"Segmentation Metrics\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.legend()\n",
        "\n",
        "    # ACCURACY\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(history[\"accuracy\"], label=\"Accuracy\")\n",
        "    plt.title(\"Accuracy Curve\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Epoch {epoch} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
        "          f\"P: {precision:.3f} R: {recall:.3f} F1: {f1:.3f} Acc: {acc:.3f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        ckpt = os.path.join(MODEL_OUT, f\"unet_best_f1_{best_f1:.4f}.pth\")\n",
        "        torch.save(model.state_dict(), ckpt)\n",
        "        print(\"Saved:\", ckpt)\n",
        "\n",
        "print(\"Training finished. Best F1:\", best_f1)"
      ],
      "metadata": {
        "id": "gjUcrd0BULB-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11602d2d-6443-4031-e384-0b5dd47e93ea"
      },
      "id": "gjUcrd0BULB-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/300:   1%|          | 14/1221 [00:08<41:13,  2.05s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckpts = sorted(glob.glob(os.path.join(MODEL_OUT, \"*.pth\")))\n",
        "ckpts"
      ],
      "metadata": {
        "id": "apJxH_48URJC"
      },
      "id": "apJxH_48URJC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full Raster Inference"
      ],
      "metadata": {
        "id": "YMfLGaGfUZyE"
      },
      "id": "YMfLGaGfUZyE"
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = \"/content/drive/MyDrive/12-training-data/models/unet_best_f1_0.8232.pth\"\n",
        "DEVICE = torch.device(\"cuda\")\n",
        "\n",
        "# Load model\n",
        "model = UNet(in_channels=NUM_FEATURE_BANDS).to(DEVICE)\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded\")"
      ],
      "metadata": {
        "id": "9Jf6p5mtUfYM"
      },
      "id": "9Jf6p5mtUfYM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape = (4531, 3714, 9)"
      ],
      "metadata": {
        "id": "cnPiAViAUdcT"
      },
      "id": "cnPiAViAUdcT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H, W, C = X.shape\n",
        "PATCH_SIZE = 64\n",
        "STRIDE = 32\n",
        "\n",
        "prob_map = np.zeros((H, W), dtype=np.float32)\n",
        "count_map = np.zeros((H, W), dtype=np.float32)\n",
        "\n",
        "for row in tqdm(range(0, H - PATCH_SIZE + 1, STRIDE)):\n",
        "    for col in range(0, W - PATCH_SIZE + 1, STRIDE):\n",
        "\n",
        "        patch = X[row:row+PATCH_SIZE, col:col+PATCH_SIZE, :]\n",
        "        patch_t = torch.from_numpy(patch).permute(2,0,1).unsqueeze(0).float().to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(patch_t)\n",
        "            probs = torch.sigmoid(logits).cpu().numpy()[0,0]\n",
        "\n",
        "        prob_map[row:row+PATCH_SIZE, col:col+PATCH_SIZE] += probs\n",
        "        count_map[row:row+PATCH_SIZE, col:col+PATCH_SIZE] += 1"
      ],
      "metadata": {
        "id": "2XEHcaZrUiuC"
      },
      "id": "2XEHcaZrUiuC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_map[count_map == 0] = 1\n",
        "final_prob_map = prob_map / count_map"
      ],
      "metadata": {
        "id": "oVO3Wm4JUktx"
      },
      "id": "oVO3Wm4JUktx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ref_path = rasters_2019[\"NDVI\"]\n",
        "\n",
        "with rasterio.open(ref_path) as src:\n",
        "    ref_profile = src.profile\n",
        "\n",
        "ref_profile.update(\n",
        "    dtype=rasterio.float32,\n",
        "    count=1,\n",
        "    compress=\"lzw\"\n",
        ")\n",
        "\n",
        "# Ensure the output directory exists\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "out_path = os.path.join(OUTPUT_DIR, \"urbanization_probability_2024.tif\")\n",
        "\n",
        "with rasterio.open(out_path, \"w\", **ref_profile) as dst:\n",
        "    dst.write(final_prob_map.astype(np.float32), 1)\n",
        "\n",
        "print(\"Saved:\", out_path)"
      ],
      "metadata": {
        "id": "TWs3B5voUnAq"
      },
      "id": "TWs3B5voUnAq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob_path = \"/content/drive/MyDrive/12-training-data/output/urbanization_probability_2024.tif\"\n",
        "\n",
        "with rasterio.open(prob_path) as src:\n",
        "    prob = src.read(1)\n",
        "    print(\"Shape:\", prob.shape)\n",
        "    print(\"Min:\", np.min(prob), \"Max:\", np.max(prob))"
      ],
      "metadata": {
        "id": "ObQlcOgIUoxm"
      },
      "id": "ObQlcOgIUoxm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(prob, cmap='viridis', vmin=0, vmax=1)\n",
        "plt.colorbar(label=\"Urbanization Probability (2019→2024)\")\n",
        "plt.title(\"Urbanization Probability Map\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iquc2Zn7UrDv"
      },
      "id": "iquc2Zn7UrDv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urban2024_path = \"/content/drive/MyDrive/12-training-data/input/dependent-data-urban-no/urban_2024.tif\"\n",
        "\n",
        "with rasterio.open(urban2024_path) as src:\n",
        "    urban24 = src.read(1)\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(prob, cmap='gray', vmin=0, vmax=1)\n",
        "plt.title(\"Predicted Probability\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(urban24, cmap='gray')\n",
        "plt.title(\"Actual Urban 2024\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UcNM9EpfUsqY"
      },
      "id": "UcNM9EpfUsqY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "history_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}